{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e8c0039",
   "metadata": {},
   "source": [
    "# Opteeq Compter Vision Project - Task B - Image Standardisation and Annotation Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515c1b90",
   "metadata": {},
   "source": [
    "This notebook will detail the process of loading, standardisation and annotation of recipt images using the Google Cloud Vision API service. The processed images will then be saved back to S3 along with annotations and a JSON file containing relevant information ready for further manual annotation by the team. \n",
    "\n",
    "The code within this notebook will be tested for functionallity before being put into scripts and ran on an AWS EC2 instance. The structure of the notebook is as follows: \n",
    "\n",
    "                    1. Things to consider\n",
    "                    2. Image read and write functions from S3 (boto3)\n",
    "                    2. Image standardisation functions using the OpenCV library\n",
    "                    3. Google Cloud Vision API call function\n",
    "                    4. Main program testing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9bff8c",
   "metadata": {},
   "source": [
    "# 1. Things to consider "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a43ed0",
   "metadata": {},
   "source": [
    "    - File naming convention (uuid? timestamp? Annotation files with matching uuid?)\n",
    "    - Image format ? JPEG only?? \n",
    "    - JSON file structure (100 images per file?, tags? Image and annotation URIs?)\n",
    "    - Build requirements.txt file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e7b61e",
   "metadata": {},
   "source": [
    "# File naming conventions: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0748aaed",
   "metadata": {},
   "source": [
    "Image = {uuid1}_{unix_timestamp}.jpeg\n",
    "\n",
    "Annotations = {uuid1}_{unix_timestamp}.csv\n",
    "\n",
    "JSON = standardised_annotated_imgs_{uuid(n)}_{unix_timestamp}_{team_member_name}.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643246e6",
   "metadata": {},
   "source": [
    "# S3 bucket file structure: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbb000f",
   "metadata": {},
   "source": [
    "    -bucket_name\n",
    "        -data\n",
    "            -unprocessed_data\n",
    "                -raw_imgs\n",
    "                    img1\n",
    "                    img2\n",
    "                    img3 \n",
    "            -standardised_annotated_data  \n",
    "                -img_annotations\n",
    "                -standardised_imgs\n",
    "                -json_files\n",
    "                    -team_member_1\n",
    "                    -team_member_2\n",
    "                    -team_member_3 \n",
    "            -fully_processed_data\n",
    "                -processed_imgs\n",
    "                -img_annotations\n",
    "                -json_files\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db68e270",
   "metadata": {},
   "source": [
    "# JSON file structure: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed0170a",
   "metadata": {},
   "source": [
    "    -100 examples per file\n",
    "    -1 team member per file\n",
    "\n",
    "    json_structure = {\n",
    "                {\n",
    "                    \"bucket\": \"bucket_name\", \n",
    "                    \"key\": \"data/standardised_annotated_data/standardised_imgs/{uuid1}_{unix_timestamp}.jpeg\", \n",
    "                    \"annotations\": \"data/standardised_annotated_data/img_annotations/{uuid1}_{unix_timestamp}.csv\", \n",
    "                    \"tags\": \"team_member1_name\"\n",
    "                },\n",
    "                {\n",
    "                    \"bucket\": \"bucket_name\", \n",
    "                    \"key\": \"data/standardised_annotated_data/standardised_imgs/{uuid2}_{unix_timestamp}.jpeg\", \n",
    "                    \"annotations\": \"data/standardised_annotated_data/img_annotations/{uuid2}_{unix_timestamp}.csv\", \n",
    "                    \"tags\": \"team_member1_name\"\n",
    "                },\n",
    "                {\n",
    "                    \"bucket\": \"bucket_name\", \n",
    "                    \"key\": \"data/standardised_annotated_data/standardised_imgs/{uuid3}_{unix_timestamp}.jpeg\", \n",
    "                    \"annotations\": \"data/standardised_annotated_data/img_annotations/{uuid3}_{unix_timestamp}.csv\", \n",
    "                    \"tags\": \"team_member1_name\"\n",
    "                }\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6674c8b2",
   "metadata": {},
   "source": [
    "# 2. S3 read/write"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562b1f07",
   "metadata": {},
   "source": [
    "We need to load all image files saved in a directory from an AWS S3 bucket. We can perform this task using the low level python sdk boto3 to interact with S3 from our EC2 instance. \n",
    "\n",
    "To begin we can use boto3 to access the location in the S3 bucket where the files are saved and find all of the image files in this location by reading only files with common image extensions compatible with OpenCV ('.JPEG', '.PNG', '.TIFF').  \n",
    "\n",
    "Next we can loop through the image URIs and load each image using the OpenCV python module and store the images in an array ready for processing. Images can be loaded in as grayscale images to save memory.\n",
    "\n",
    "When writing our information back to S3 we need to save the processed images with a specified file naming convention with a unique id, the csv files containing the annotations as well as JSON files containing the paths to the images the annotation csv file and a tag of the team member responsable for manually annotating the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fa340c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "def get_image_paths_from_S3(bucket_name=\"bucket_name\", key=\"data/unprocessed_data/raw_imgs\"): \n",
    "    \"\"\"Procedure: Using the boto\n",
    "    -------\n",
    "    Input\n",
    "    -------\n",
    "    bucket: String object containing S3 bucket name\n",
    "    key: String object containing path to folder containing unprocessed images\n",
    "    -------\n",
    "    Output\n",
    "    -------\n",
    "    s3_image_paths: List object containing strings of paths to S3 locations where each image is located \n",
    "    \"\"\"\n",
    "    \n",
    "    s3_img_paths = [] # List declaration to store image path locations\n",
    "    \n",
    "    try: # Try to read s3 bucket\n",
    "        for obj in s3_client.list_objects_v2(Bucket=bucket_name, Prefix=key)['Contents']: # Loop through bucket directory contents\n",
    "            if obj.endswith('.jpeg') or obj.endswith('.png') or obj.endswith('.tiff'):  # Check file extension\n",
    "                s3_img_paths.append(obj) # If extension is ok append path to list\n",
    "            else: \n",
    "                print(\"File not a compatible image file, must be of extension '.jpeg', '.png', '.tiff'.\") # Else print warning\n",
    "    except: # If try fails catch and print error message\n",
    "        print(\"Error, could not retrieve image paths from s3 location: {}/{}\".format(bucket_name, key)) \n",
    "    \n",
    "    return s3_img_paths\n",
    "    \n",
    "\n",
    "def s3_image_read(bucket_name=\"bucket_name\", key):\n",
    "    \"\"\"Procedure:\n",
    "    -------\n",
    "    Input\n",
    "    -------\n",
    "    bucket: String object containing S3 bucket name\n",
    "    key: String object containing S3 uri to an image\n",
    "    -------\n",
    "    Output\n",
    "    -------\n",
    "    img: Numpy array of image\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = bucket.Object(key).get().get('Body').read()\n",
    "        nparray = cv2.imdecode(np.asarray(bytearray(img)), cv2.IMREAD_GRAYSCALE)\n",
    "    except: \n",
    "        print(\"Error, image file could not be loaded.\")\n",
    "        \n",
    "    return nparray\n",
    "\n",
    "def s3_write(bucket, key, img, ): \n",
    "    \"\"\"Procedure:\n",
    "    -------\n",
    "    Input:\n",
    "    -------\n",
    "\n",
    "    -------\n",
    "    Output: \n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    return message\n",
    "\n",
    "def json_write(): \n",
    "    \"\"\"Procedure:\n",
    "    -------\n",
    "    Input:\n",
    "    -------\n",
    "\n",
    "    -------\n",
    "    Output: \n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    return message\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2824bd6",
   "metadata": {},
   "source": [
    "# 3. Image standardisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dbdeff",
   "metadata": {},
   "source": [
    "During image standardisation we need to perform several operations to prepare images for annotation using the GCloud Vision API. This includes orienting the image correctly, ensuring that images have a minimum size and that the ratio of the images is suitable. \n",
    "\n",
    "Image ratio check - \n",
    "\n",
    "Resize image - Resize image keeping ratio the same\n",
    "\n",
    "Orientation - Simple solution for images in landscape: Check height and width of image if width is larger than height rotate image 90 degrees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e13e06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_size(): \n",
    "    \"\"\"Procedure:\n",
    "    -------\n",
    "    Input\n",
    "    -------\n",
    "\n",
    "    -------\n",
    "    Output\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "def resize_img():\n",
    "    \"\"\"Procedure:\n",
    "    -------\n",
    "    Input\n",
    "    -------\n",
    "\n",
    "    -------\n",
    "    Output\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    return img\n",
    "    \n",
    "def check_orientation(): \n",
    "    \"\"\"Procedure:\n",
    "    -------\n",
    "    Input\n",
    "    -------\n",
    "\n",
    "    -------\n",
    "    Output\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "def rotate_image_90(): \n",
    "    \"\"\"Procedure:\n",
    "    -------\n",
    "    Input\n",
    "    -------\n",
    "\n",
    "    -------\n",
    "    Output\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2358cc19",
   "metadata": {},
   "source": [
    "# 4. Gcloud vision API request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fd8a9e",
   "metadata": {},
   "source": [
    "Build an api request to send an image to the GCloud Vision API and recieve image text and ROI (region of interest) annotations as a reponse. The JSON response will then be stored in a pandas dataframe ready to be pushed to S3 as a csv file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc7a7e8",
   "metadata": {},
   "source": [
    "#Modified code from Johann \n",
    "\n",
    "import io\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# Imports the Google Cloud client library\n",
    "from google.cloud import vision\n",
    "\n",
    "\n",
    "# Environment variable must be set before the function can be used\n",
    "# Terminal command : export GOOGLE_APPLICATION_CREDENTIALS=path_to_gcloud_credientials\n",
    "\n",
    "def generate_annotations(input_img):\n",
    "    \"\"\"Procedure: Generate a csv file with the output of googlevision API text detection\n",
    "    -------\n",
    "    Input:\n",
    "    -------\n",
    "    input_img: opencv image \n",
    "    -------\n",
    "    Output: \n",
    "    -------\n",
    "    input_img: opencv image\n",
    "    \n",
    "    result df: Pandas dataframe object containing annotations from gcloud vision api\n",
    "        index : index of the box\n",
    "        text : string\n",
    "            the text of the given box\n",
    "        box_center_x : float\n",
    "            the x coordinate of the center of the given box\n",
    "        box_center_y : float\n",
    "            the y coordinate of the center of the given box\n",
    "        box_width : int\n",
    "            the width of the given box\n",
    "        box_height : int\n",
    "            the height of the given box\n",
    "    \"\"\"\n",
    "    # Instantiates a client\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    img = vision.Image(content=input_img)\n",
    "\n",
    "    # Performs text detection on the image file\n",
    "    response = client.text_detection(image=img)\n",
    "\n",
    "    # Initialize a Dictionnary to store the results\n",
    "    result = {'text': [], 'box_center_x': [], 'box_center_y': [], 'box_width': [], 'box_height': []}\n",
    "\n",
    "    # loop over the boxes\n",
    "    for box in response.text_annotations:\n",
    "        # Text content of the box\n",
    "        text_content = box.description\n",
    "\n",
    "        # Initialize the minimum and maximum coordinates of the box\n",
    "        min_x = math.inf\n",
    "        max_x = 0\n",
    "        min_y = math.inf\n",
    "        max_y = 0\n",
    "\n",
    "        # Loop over the corners of the box to get the minimum and maximum coordinates of\n",
    "        # the corners of the box\n",
    "        for corner in box.bounding_poly.vertices:\n",
    "            if corner.x < min_x:\n",
    "                min_x = corner.x\n",
    "            if corner.x > max_x:\n",
    "                max_x = corner.x\n",
    "            if corner.y < min_y:\n",
    "                min_y = corner.y\n",
    "            if corner.y > max_y:\n",
    "                max_y = corner.y\n",
    "\n",
    "        # Calculate the center, width and height of the box\n",
    "        box_width = max_x - min_x\n",
    "        box_height = max_y - min_y\n",
    "        box_center_x = min_x + (box_width / 2)\n",
    "        box_center_y = min_y + (box_height / 2)\n",
    "\n",
    "        # Store the results in the Dictionnary\n",
    "        result['text'].append(text_content)\n",
    "        result['box_center_x'].append(box_center_x)\n",
    "        result['box_center_y'].append(box_center_y)\n",
    "        result['box_width'].append(box_width)\n",
    "        result['box_height'].append(box_height)\n",
    "\n",
    "    # Store results in a pandas dataframe \n",
    "    result_df = pd.DataFrame(result)\n",
    "    return input_img, result_df\n",
    "\n",
    "# To Test of the function, uncomment the following lines\n",
    "#file_name = os.path.abspath('1192-receipt.jpg')\n",
    "#generate_annotations(file_name, 'output.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef157f1",
   "metadata": {},
   "source": [
    "# 5. Main program function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1a5b43",
   "metadata": {},
   "source": [
    "The main program function will execute all of the functions in this notebook for a small number of images ~10 to begin with to test functionallity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164bfeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Procedure:\n",
    "    -------\n",
    "    Input\n",
    "    -------\n",
    "\n",
    "    -------\n",
    "    Output\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    # Get paths from S3 bucket and load images into list of numpy arrays\n",
    "    \n",
    "    # Process images \n",
    "    \n",
    "    # Send images to GCloud vision API \n",
    "    \n",
    "    # Save images, annotations and JSON file to S3 \n",
    "    \n",
    "    return 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (DSTI-Opteeq)",
   "language": "python",
   "name": "pycharm-778e655e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
